{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: arxiv in c:\\users\\hamza\\miniconda3\\envs\\updlang\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: feedparser~=6.0.10 in c:\\users\\hamza\\miniconda3\\envs\\updlang\\lib\\site-packages (from arxiv) (6.0.12)\n",
      "Requirement already satisfied: requests~=2.32.0 in c:\\users\\hamza\\miniconda3\\envs\\updlang\\lib\\site-packages (from arxiv) (2.32.5)\n",
      "Requirement already satisfied: sgmllib3k in c:\\users\\hamza\\miniconda3\\envs\\updlang\\lib\\site-packages (from feedparser~=6.0.10->arxiv) (1.0.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hamza\\miniconda3\\envs\\updlang\\lib\\site-packages (from requests~=2.32.0->arxiv) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hamza\\miniconda3\\envs\\updlang\\lib\\site-packages (from requests~=2.32.0->arxiv) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hamza\\miniconda3\\envs\\updlang\\lib\\site-packages (from requests~=2.32.0->arxiv) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hamza\\miniconda3\\envs\\updlang\\lib\\site-packages (from requests~=2.32.0->arxiv) (2025.10.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper=WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=200)\n",
    "wiki=WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_13072\\3562451817.py:9: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the `langchain-ollama package and should be used instead. To use it run `pip install -U `langchain-ollama` and import as `from `langchain_ollama import OllamaEmbeddings``.\n",
      "  vectordb=FAISS.from_documents(documents,OllamaEmbeddings(model='mxbai-embed-large'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000019646755290>, search_kwargs={})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader=WebBaseLoader(\"https://docs.smith.langchain.com/\")\n",
    "docs=loader.load()\n",
    "documents=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200).split_documents(docs)\n",
    "vectordb=FAISS.from_documents(documents,OllamaEmbeddings(model='mxbai-embed-large'))\n",
    "retriever=vectordb.as_retriever()\n",
    "retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.tools.retriever import create_retriever_tool\n",
    "retriever_tool=create_retriever_tool(retriever,\"langsmith_search\",\n",
    "                      \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langsmith_search'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Arxiv Tool\n",
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun\n",
    "\n",
    "arxiv_wrapper=ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=500)\n",
    "arxiv=ArxivQueryRun(api_wrapper=arxiv_wrapper)\n",
    "arxiv.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[wiki,arxiv,retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\hamza\\\\miniconda3\\\\envs\\\\updLang\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=500)),\n",
       " Tool(name='langsmith_search', description='Search for information about LangSmith. For any questions about LangSmith, you must use this tool!', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x00000196696B02C0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000019646755290>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x00000196696B0400>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000019646755290>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_groq import ChatGroq\n",
    "load_dotenv()\n",
    "import os\n",
    "# os.environ['Ollama_API_KEY']=os.getenv(\"Ollama_API_KEY\")\n",
    "\n",
    "llm = ChatGroq(model=\"meta-llama/llama-4-maverick-17b-128e-instruct\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react', 'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'}, template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_classic import hub\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Agents\n",
    "from langchain_classic.agents import create_react_agent\n",
    "agent=create_react_agent(llm,tools,prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_log_to_str(x['intermediate_steps']))\n",
       "})\n",
       "| PromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={}, partial_variables={'tools': 'wikipedia - A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\narxiv - A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.\\nlangsmith_search(query: \\'str\\', *, retriever: \\'BaseRetriever\\' = VectorStoreRetriever(tags=[\\'FAISS\\', \\'OllamaEmbeddings\\'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000019646755290>, search_kwargs={}), document_prompt: \\'BasePromptTemplate\\' = PromptTemplate(input_variables=[\\'page_content\\'], input_types={}, partial_variables={}, template=\\'{page_content}\\'), document_separator: \\'str\\' = \\'\\\\n\\\\n\\', callbacks: \\'Callbacks\\' = None, response_format: \"Literal[\\'content\\', \\'content_and_artifact\\']\" = \\'content\\') -> \\'str | tuple[str, list[Document]]\\' - Search for information about LangSmith. For any questions about LangSmith, you must use this tool!', 'tool_names': 'wikipedia, arxiv, langsmith_search'}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react', 'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'}, template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000196DB0FF550>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000196DB11EA10>, model_name='meta-llama/llama-4-maverick-17b-128e-instruct', temperature=1e-08, model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'stop': ['\\nObservation']}, config={}, config_factories=[])\n",
       "| ReActSingleInputOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\hamza\\\\miniconda3\\\\envs\\\\updLang\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=500)), Tool(name='langsmith_search', description='Search for information about LangSmith. For any questions about LangSmith, you must use this tool!', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x00000196696B02C0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000019646755290>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x00000196696B0400>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000019646755290>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Agent Executer\n",
    "from langchain_classic.agents import AgentExecutor\n",
    "agent_executor=AgentExecutor(agent=agent,tools=tools,verbose=True)\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo answer the question about Langsmith, I need to use the langsmith_search tool, as it is specifically designed for searching information about LangSmith.\n",
      "\n",
      "Action: langsmith_search\n",
      "Action Input: LangSmith overview\u001b[0m\u001b[38;5;200m\u001b[1;3mCopy the key and save it securely.\n",
      "Once your account and API key are ready, choose a quickstart to begin building with LangSmith:\n",
      "ObservabilityGain visibility into every step your application takes to debug faster and improve reliability.Start tracingEvaluationMeasure and track quality over time to ensure your AI applications are consistent and trustworthy.Evaluate your appDeploymentDeploy your agents as LangGraph Servers, ready to scale in production.Deploy your agentsPrompt TestingIterate on prompts with built-in versioning and collaboration to ship improvements faster.Test your promptsStudioUse a visual interface to design, test, and refine applications end-to-end.Develop with StudioHostingHost LangSmith in the cloud, in your environment, or hybrid to match your infrastructure and compliance needs.Choose your hosting mode\n",
      "​Workflow\n",
      "LangSmith combines observability, evaluation, deployment, and hosting in one integrated workflow—from local development to production.\n",
      "\n",
      "LangSmith docs - Docs by LangChainSkip to main contentWe've raised a $125M Series B to build the platform for agent engineering. Read more.Docs by LangChain home pageLangSmithSearch...⌘KGitHubTry LangSmithTry LangSmithSearch...NavigationLangSmith docsGet startedObservabilityEvaluationPrompt engineeringDeploymentAgent BuilderHostingOverviewPlansCreate an account and API keyAccount administrationOverviewSet up a workspaceManage organizations using the APIManage billingSet up resource tagsUser managementReferenceLangSmith Python SDKLangSmith JS/TS SDKLangGraph Python SDKLangGraph JS/TS SDKLangSmith APIAPI reference for LangSmith DeploymentAdditional resourcesReleases & changelogsData managementScalability & resilienceAuthentication methodsFAQsRegions FAQPricing FAQLangSmith docsCopy pageCopy pageLangSmith provides tools for developing, debugging, and deploying LLM applications.\n",
      "It helps you trace requests, evaluate outputs, test prompts, and manage deployments in one place.\n",
      "\n",
      "It helps you trace requests, evaluate outputs, test prompts, and manage deployments in one place.\n",
      "LangSmith is framework agnostic, so you can use it with or without LangChain’s open-source libraries\n",
      "langchain and langgraph.\n",
      "Prototype locally, then move to production with integrated monitoring and evaluation to build more reliable AI systems.\n",
      "LangGraph Platform is now LangSmith Deployment. For more information, check out the Changelog.\n",
      "​Get started\n",
      "Create an accountSign up at smith.langchain.com (no credit card required).\n",
      "You can log in with Google, GitHub, or email.Create an API keyGo to your Settings page → API Keys → Create API Key.\n",
      "Copy the key and save it securely.\n",
      "Once your account and API key are ready, choose a quickstart to begin building with LangSmith:\n",
      "\n",
      "Edit the source of this page on GitHub.\n",
      "Connect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.Was this page helpful?YesNoPricing plansNext⌘IDocs by LangChain home pagegithubxlinkedinyoutubeResourcesForumChangelogLangChain AcademyTrust CenterCompanyAboutCareersBloggithubxlinkedinyoutubePowered by Mintlify\u001b[0m\u001b[32;1m\u001b[1;3mThought: I have gathered information about LangSmith using the langsmith_search tool. Now, I will summarize the findings to provide a comprehensive answer.\n",
      "\n",
      "Final Answer: LangSmith is a platform that provides tools for developing, debugging, and deploying LLM (Large Language Model) applications. It offers features such as observability, evaluation, deployment, and hosting in an integrated workflow. LangSmith allows users to trace requests, evaluate outputs, test prompts, and manage deployments in one place. It is framework-agnostic, meaning it can be used with or without LangChain's open-source libraries. Users can prototype locally and then move to production with integrated monitoring and evaluation to build more reliable AI systems. To get started, users need to create an account and API key on the LangSmith website.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me about Langsmith',\n",
       " 'output': \"LangSmith is a platform that provides tools for developing, debugging, and deploying LLM (Large Language Model) applications. It offers features such as observability, evaluation, deployment, and hosting in an integrated workflow. LangSmith allows users to trace requests, evaluate outputs, test prompts, and manage deployments in one place. It is framework-agnostic, meaning it can be used with or without LangChain's open-source libraries. Users can prototype locally and then move to production with integrated monitoring and evaluation to build more reliable AI systems. To get started, users need to create an account and API key on the LangSmith website.\"}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"Tell me about Langsmith\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo determine what the paper 1605.08386 is about, I need to search for it on a platform that hosts scientific articles. Arxiv.org is a well-known repository for electronic preprints in physics, mathematics, computer science, and related disciplines, and it uses a format like \"1605.08386\" to identify papers.\n",
      "\n",
      "Thought: The identifier \"1605.08386\" is in the format used by Arxiv.org, indicating it's an Arxiv identifier. I should search for this identifier on Arxiv.\n",
      "\n",
      "Action: arxiv\n",
      "Action Input: 1605.08386\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPublished: 2016-05-26\n",
      "Title: Heat-bath random walks with Markov bases\n",
      "Authors: Caprice Stanley, Tobias Windisch\n",
      "Summary: Graphs on lattice points are studied whose edges come from a finite set of\n",
      "allo\u001b[0m\u001b[32;1m\u001b[1;3mThought: The observation provides the title and a partial summary of the paper. To get the full context, I need to understand the paper is about \"Heat-bath random walks with Markov bases.\" I will now search for more information about this title on Arxiv or related scientific contexts.\n",
      "\n",
      "Action: arxiv\n",
      "Action Input: Heat-bath random walks with Markov bases\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mNo good Arxiv Result was found\u001b[0m\u001b[32;1m\u001b[1;3mIt seems that searching for the exact title didn't yield additional results. However, I already have the title and a partial summary from the initial search. To provide a more comprehensive answer, I can use the information obtained so far.\n",
      "\n",
      "Thought: The paper \"1605.08386\" is titled \"Heat-bath random walks with Markov bases\" by Caprice Stanley and Tobias Windisch. It's about graphs on lattice points whose edges come from a finite set of allowed moves, related to the concept of heat-bath random walks and Markov bases.\n",
      "\n",
      "I now know the final answer.\n",
      "\n",
      "Final Answer: The paper \"1605.08386\" is titled \"Heat-bath random walks with Markov bases\" and discusses graphs on lattice points with edges derived from a finite set of allowed moves, in the context of heat-bath random walks and Markov bases.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"What's the paper 1605.08386 about?\",\n",
       " 'output': 'The paper \"1605.08386\" is titled \"Heat-bath random walks with Markov bases\" and discusses graphs on lattice points with edges derived from a finite set of allowed moves, in the context of heat-bath random walks and Markov bases.'}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"What's the paper 1605.08386 about?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo find out what the paper 2405.12255 is about, I need to search for it on a platform that hosts scientific articles. Arxiv is a repository of electronic preprints in physics, mathematics, computer science, and related disciplines, making it a suitable source for this information.\n",
      "\n",
      "Action: arxiv\n",
      "Action Input: 2405.12255\u001b[0m\u001b[33;1m\u001b[1;3mPublished: 2024-05-22\n",
      "Title: Mammo-CLIP: A Vision Language Foundation Model to Enhance Data Efficiency and Robustness in Mammography\n",
      "Authors: Shantanu Ghosh, Clare B. Poynton, Shyam Visweswaran, Kayhan Batmanghelich\n",
      "Summary: The lack of large and diverse training data on Computer-Aided Diagnosis (CAD)\n",
      "in breast cancer detection has been one of the concerns that impedes the\n",
      "adoption of the system. Recently, pre-training with large-scale image text\n",
      "datasets via Vision-Language models (VLM) (\\eg CL\u001b[0m\u001b[32;1m\u001b[1;3mThought: The observation provides the title and summary of the paper 2405.12255. The paper is titled \"Mammo-CLIP: A Vision Language Foundation Model to Enhance Data Efficiency and Robustness in Mammography\" and discusses using Vision-Language models to improve Computer-Aided Diagnosis in breast cancer detection by enhancing data efficiency and robustness.\n",
      "\n",
      "I now know the final answer.\n",
      "\n",
      "Final Answer: The paper 2405.12255, titled \"Mammo-CLIP: A Vision Language Foundation Model to Enhance Data Efficiency and Robustness in Mammography,\" discusses enhancing data efficiency and robustness in mammography using a Vision-Language foundation model, specifically to address the lack of large and diverse training data for Computer-Aided Diagnosis in breast cancer detection.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"What's the paper 2405.12255 about?\",\n",
       " 'output': 'The paper 2405.12255, titled \"Mammo-CLIP: A Vision Language Foundation Model to Enhance Data Efficiency and Robustness in Mammography,\" discusses enhancing data efficiency and robustness in mammography using a Vision-Language foundation model, specifically to address the lack of large and diverse training data for Computer-Aided Diagnosis in breast cancer detection.'}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"What's the paper 2405.12255 about?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "updLang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
